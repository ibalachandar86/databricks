Below is a complete, production-ready Databricks SCD Type-2 (Slowly Changing Dimensions Type 2) pipeline that copies CDC data from Bronze ‚Üí Silver with full history tracking.

This example works for:

CDC feed containing I / U / D ops

Maintains valid_from, valid_to, is_current

Automatically closes old records and inserts new versions

Handles deletes (optional ‚Äî soft delete)



---

‚úÖ SCD2 Target Columns (Silver Table)

Your Silver table will have these fields:

Column	Description

id	Business key
value	Current attribute
valid_from	Record start timestamp
valid_to	Record end timestamp
is_current	Boolean flag
op	CDC operation (optional)



---

üìò 1. Bronze CDC Table Example

Assume Bronze table: bronze.customer_cdc

id | name | city | op | ts

Where op = I, U, D.


---

üöÄ 2. Create Silver SCD2 Table (if not exists)

CREATE TABLE IF NOT EXISTS silver.customer_scd2 (
  id           STRING,
  name         STRING,
  city         STRING,
  valid_from   TIMESTAMP,
  valid_to     TIMESTAMP,
  is_current   BOOLEAN,
  op           STRING
)
USING delta;


---

‚≠ê 3. Full PySpark Code ‚Äî SCD2 Merge Logic

This is the complete working SCD Type 2 logic using MERGE.

from delta.tables import DeltaTable
from pyspark.sql.functions import current_timestamp, col, lit

# Read bronze CDC feed
bronze_df = spark.read.table("bronze.customer_cdc")

# Prepare fields needed for SCD2
bronze_df = (
    bronze_df
    .withColumn("valid_from", col("ts"))
    .withColumn("valid_to", lit(None).cast("timestamp"))
    .withColumn("is_current", lit(True))
)

silver = DeltaTable.forName(spark, "silver.customer_scd2")

# Step 1: Close out old records where changes occur
silver.alias("t").merge(
    bronze_df.alias("s"),
    "t.id = s.id AND t.is_current = True"
).whenMatchedUpdate(
    condition = "s.op IN ('U', 'D')",
    set = {
        "valid_to": "s.ts",
        "is_current": "false"
    }
).execute()

# Step 2: Insert new versions for INSERT or UPDATE ops
silver.alias("t").merge(
    bronze_df.alias("s"),
    "t.id = s.id AND t.is_current = True"
).whenNotMatchedInsert(
    condition = "s.op IN ('I', 'U')",
    values = {
        "id": "s.id",
        "name": "s.name",
        "city": "s.city",
        "valid_from": "s.valid_from",
        "valid_to": "s.valid_to",
        "is_current": "s.is_current",
        "op": "s.op"
    }
).execute()

# Step 3: Optional soft-delete handling (op = 'D')
silver.alias("t").merge(
    bronze_df.alias("s"),
    "t.id = s.id"
).whenNotMatchedInsert(
    condition="s.op = 'D'",
    values={
        "id": "s.id",
        "name": lit(None),
        "city": lit(None),
        "valid_from": "s.valid_from",
        "valid_to": "s.valid_to",
        "is_current": lit(False),
        "op": "s.op"
    }
).execute()


---

üåü What This Code Does

‚úî Updates (U)

Closes the previous version (valid_to = ts, is_current = False)

Inserts a new version with is_current = True


‚úî Inserts (I)

Direct insert as a new version


‚úî Deletes (D)

Closes the current version

Inserts a soft-deleted version (optional)



---

üß† Final Silver Table Example

id	name	city	valid_from	valid_to	is_current

1	Alice	NY	2024-01-01	2024-02-10	false
1	Alice	LA	2024-02-10	NULL	true



---

üìå Want a Delta Live Tables Version?

I can generate a full DLT SCD2 pipeline (Python or SQL), including:

JSON config

Auto Loader ingestion

Stream-to-stream CDC SCD2 merge


Just tell me: ‚ÄúGive me DLT SCD2 version‚Äù
